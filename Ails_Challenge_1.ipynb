{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oia4DCDpaXKA"
      },
      "source": [
        "# Drug Activity Prediction using SVM , Random forest and DeepChem\n",
        "\n",
        "Prediction different assays activities based on their molecule structure\n",
        "\n",
        "By: Khaled Yousef "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyPiGA7qa7dZ",
        "outputId": "7082886f-eda1-4b27-ea8c-223df45ae8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (from deepchem) (2022.3.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deepchem) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing Deepchem\n",
        "# Installing conda\n",
        "\n",
        "!pip install --pre deepchem\n",
        "# Import deepchem just to check the version\n",
        "\n",
        "# Importing required libraries and its utilities\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(123)\n",
        "import deepchem as dc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plot\n",
        "from deepchem.molnet import load_tox21\n",
        "from deepchem.models.graph_models import GraphConvModel\n",
        "from rdkit import Chem\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import argparse\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DvxQ1iaz4Tl",
        "outputId": "fa5583ad-43a1-4f0d-f7e5-6157211b560c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "bsGQo9e2BouB",
        "outputId": "49be69c0-257d-49c6-a207-161a0f145ab8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-990cab6e-9333-40c6-a088-a2c5f86aaf86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>task11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(=O)N(C)c1cccc(-c2ccnc3c(C(=O)c4cccs4)cnn23)c1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COc1cc(N)c(Cl)cc1C(=O)OCCCN1CCCCC1.Cl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCCCNc1c(C(=O)OCC)cnc2c1cnn2CC</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C#Cc1cccc(Nc2ncnc3cc(OCCOC)c(OCCOC)cc23)c1.Cl</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC1OC2(CCCCC2Oc2cccc(Cl)c2)N=C1O</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11115</th>\n",
              "      <td>CC(C)(C)NC[C@@H](O)COc1nsnc1N1CCOCC1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11116</th>\n",
              "      <td>CCC[C@@]1(CCc2ccccc2)CC(O)=C([C@H](CC)c2cccc(N...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11117</th>\n",
              "      <td>N=C(O)c1cnc(C2CC2)[nH]1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11118</th>\n",
              "      <td>CN=C=O</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11119</th>\n",
              "      <td>Cc1ccc2c(c1N)C(=O)c1ccccc1C2=O</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11120 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-990cab6e-9333-40c6-a088-a2c5f86aaf86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-990cab6e-9333-40c6-a088-a2c5f86aaf86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-990cab6e-9333-40c6-a088-a2c5f86aaf86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  smiles  task11\n",
              "0       CC(=O)N(C)c1cccc(-c2ccnc3c(C(=O)c4cccs4)cnn23)c1       0\n",
              "1                  COc1cc(N)c(Cl)cc1C(=O)OCCCN1CCCCC1.Cl       0\n",
              "2                         CCCCNc1c(C(=O)OCC)cnc2c1cnn2CC       0\n",
              "3          C#Cc1cccc(Nc2ncnc3cc(OCCOC)c(OCCOC)cc23)c1.Cl       1\n",
              "4                       CC1OC2(CCCCC2Oc2cccc(Cl)c2)N=C1O       0\n",
              "...                                                  ...     ...\n",
              "11115               CC(C)(C)NC[C@@H](O)COc1nsnc1N1CCOCC1       0\n",
              "11116  CCC[C@@]1(CCc2ccccc2)CC(O)=C([C@H](CC)c2cccc(N...       0\n",
              "11117                            N=C(O)c1cnc(C2CC2)[nH]1       0\n",
              "11118                                             CN=C=O       0\n",
              "11119                     Cc1ccc2c(c1N)C(=O)c1ccccc1C2=O       0\n",
              "\n",
              "[11120 rows x 2 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Split the training dataset by task and removing the -1 samples  to ease the processing for Graph convolutions classifications\n",
        "whole_training_data = df = pd.read_csv(\"/content/drive/MyDrive/Drug Activity Challenge/data_train.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "task1_df = whole_training_data[['smiles','task1']]\n",
        "task1_df.drop(task1_df[task1_df.task1 == -1].index,inplace = True)\n",
        "task1_df = task1_df.reset_index(drop = True)\n",
        "task1_df.to_csv('task1.csv')\n",
        "task1_df\n",
        "\n",
        "####\n",
        "\n",
        "task2_df = whole_training_data[['smiles','task2']]\n",
        "task2_df.drop(task2_df[task2_df.task2 == -1].index,inplace = True)\n",
        "task2_df = task2_df.reset_index(drop = True)\n",
        "task2_df.to_csv('task2.csv')\n",
        "task2_df\n",
        "\n",
        "\n",
        "##\n",
        "\n",
        "task3_df = whole_training_data[['smiles','task3']]\n",
        "task3_df.drop(task3_df[task3_df.task3 == -1].index,inplace = True)\n",
        "task3_df = task3_df.reset_index(drop = True)\n",
        "task3_df.to_csv('task3.csv')\n",
        "task3_df\n",
        "\n",
        "\n",
        "###\n",
        "\n",
        "task4_df = whole_training_data[['smiles','task4']]\n",
        "task4_df.drop(task4_df[task4_df.task4 == -1].index,inplace = True)\n",
        "task4_df = task4_df.reset_index(drop = True)\n",
        "task4_df.to_csv('task4.csv')\n",
        "task4_df\n",
        "###\n",
        "\n",
        "task5_df = whole_training_data[['smiles','task5']]\n",
        "task5_df.drop(task5_df[task5_df.task5 == -1].index,inplace = True)\n",
        "task5_df = task5_df.reset_index(drop = True)\n",
        "task5_df.to_csv('task5.csv')\n",
        "task5_df\n",
        "\n",
        "###\n",
        "task6_df = whole_training_data[['smiles','task6']]\n",
        "task6_df.drop(task6_df[task6_df.task6 == -1].index,inplace = True)\n",
        "task6_df = task6_df.reset_index(drop = True)\n",
        "task6_df.to_csv('task6.csv')\n",
        "task6_df\n",
        "\n",
        "###\n",
        "\n",
        "task7_df = whole_training_data[['smiles','task7']]\n",
        "task7_df.drop(task7_df[task7_df.task7 == -1].index,inplace = True)\n",
        "task7_df = task7_df.reset_index(drop = True)\n",
        "task7_df.to_csv('task7.csv')\n",
        "task7_df\n",
        "\n",
        "###\n",
        "\n",
        "task8_df = whole_training_data[['smiles','task8']]\n",
        "task8_df.drop(task8_df[task8_df.task8 == -1].index,inplace = True)\n",
        "task8_df = task8_df.reset_index(drop = True)\n",
        "task8_df.to_csv('task8.csv')\n",
        "task8_df\n",
        "\n",
        "###\n",
        "\n",
        "task9_df = whole_training_data[['smiles','task9']]\n",
        "task9_df.drop(task9_df[task9_df.task9 == -1].index,inplace = True)\n",
        "task9_df = task9_df.reset_index(drop = True)\n",
        "task9_df.to_csv('task9.csv')\n",
        "task9_df\n",
        "\n",
        "###\n",
        "\n",
        "task10_df = whole_training_data[['smiles','task10']]\n",
        "task10_df.drop(task10_df[task10_df.task10 == -1].index,inplace = True)\n",
        "task10_df = task10_df.reset_index(drop = True)\n",
        "task10_df.to_csv('task10.csv')\n",
        "task10_df\n",
        "\n",
        "###\n",
        "\n",
        "task11_df = whole_training_data[['smiles','task11']]\n",
        "task11_df.drop(task11_df[task11_df.task11 == -1].index,inplace = True)\n",
        "task11_df = task11_df.reset_index(drop = True)\n",
        "task11_df.to_csv('task11.csv')\n",
        "task11_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "romK0kpoDMOe",
        "outputId": "da255f49-24cb-43c1-c7f7-d0ec40e392a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n",
            "/usr/local/lib/python3.7/dist-packages/deepchem/data/data_loader.py:163: FutureWarning: featurize() is deprecated and has been renamed to create_dataset().featurize() will be removed in DeepChem 3.0\n",
            "  \"featurize() will be removed in DeepChem 3.0\", FutureWarning)\n",
            "smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n"
          ]
        }
      ],
      "source": [
        "#Featurize the data\n",
        "\n",
        "task1 = ['task1']\n",
        "task2 = ['task2']\n",
        "task3 = ['task3']\n",
        "task4 = ['task4']\n",
        "task5 = ['task5']\n",
        "task6 = ['task6']\n",
        "task7 = ['task7']\n",
        "task8 = ['task8']\n",
        "task9 = ['task9']\n",
        "task10 = ['task10']\n",
        "task11 = ['task11']\n",
        "\n",
        "featurizer=dc.feat.ConvMolFeaturizer()\n",
        "\n",
        "# load data and calculate the features for dataset\n",
        "\n",
        "loader_1 = dc.data.CSVLoader(tasks=task1, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_1=loader_1.featurize('/content/task1.csv')\n",
        "\n",
        "loader_2 = dc.data.CSVLoader(tasks=task2, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_2=loader_2.featurize('/content/task2.csv')\n",
        "\n",
        "loader_3 = dc.data.CSVLoader(tasks=task3, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_3=loader_3.featurize('/content/task3.csv')\n",
        "\n",
        "loader_4 = dc.data.CSVLoader(tasks=task4, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_4=loader_4.featurize('/content/task4.csv')\n",
        "\n",
        "loader_5 = dc.data.CSVLoader(tasks=task5, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_5=loader_5.featurize('/content/task5.csv')\n",
        "\n",
        "loader_6 = dc.data.CSVLoader(tasks=task6, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_6=loader_6.featurize('/content/task6.csv')\n",
        "\n",
        "loader_7 = dc.data.CSVLoader(tasks=task7, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_7=loader_7.featurize('/content/task7.csv')\n",
        "\n",
        "loader_8 = dc.data.CSVLoader(tasks=task8, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_8=loader_8.featurize('/content/task8.csv')\n",
        "\n",
        "loader_9 = dc.data.CSVLoader(tasks=task9, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_9=loader_9.featurize('/content/task9.csv')\n",
        "\n",
        "loader_10 = dc.data.CSVLoader(tasks=task10, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_10=loader_10.featurize('/content/task10.csv')\n",
        "\n",
        "loader_11 = dc.data.CSVLoader(tasks=task11, smiles_field=\"smiles\",featurizer=featurizer)\n",
        "dataset_11=loader_11.featurize('/content/task11.csv')\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3vSMvs4BYwC"
      },
      "outputs": [],
      "source": [
        "dataset = dataset_1\n",
        "\n",
        "\n",
        "\n",
        "# define a transformer for data using only training subset!\n",
        "transformers = [\n",
        "                dc.trans.BalancingTransformer(dataset=dataset)]\n",
        "\n",
        "# apply transformation to all datasets including the external \n",
        "for transformer in transformers:  \n",
        "  dataset = transformer.transform(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuCaMFR8chWD"
      },
      "outputs": [],
      "source": [
        "#Defining the Metrics\n",
        "\n",
        "# define mean AUROC metrics for the classifier\n",
        "metric = dc.metrics.Metric(\n",
        "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "# define number of internal features\n",
        "n_feat = 75\n",
        "\n",
        "# define batch size during the training\n",
        "batch_size = 32\n",
        "\n",
        "# dropout \n",
        "n_dropout = 0.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qrE8ynmE5nf",
        "outputId": "6d363a4f-d52c-4973-fbe4-c7059b8c6d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset samples : 11050\n",
            "Train dataset samples : 8840\n",
            "Validation dataset samples : 2210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_14:0\", shape=(175,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_13:0\", shape=(175, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_17:0\", shape=(768,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_16:0\", shape=(768, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_20:0\", shape=(723,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_19:0\", shape=(723, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_23:0\", shape=(56,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_22:0\", shape=(56, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_11:0\", shape=(175,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_10:0\", shape=(175, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_13:0\", shape=(768,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_12:0\", shape=(768, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_15:0\", shape=(723,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_14:0\", shape=(723, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_17:0\", shape=(56,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_16:0\", shape=(56, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_14:0\", shape=(175,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_13:0\", shape=(175, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_17:0\", shape=(768,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_16:0\", shape=(768, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_20:0\", shape=(723,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_19:0\", shape=(723, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_23:0\", shape=(56,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_22:0\", shape=(56, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_14:0\", shape=(154,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_13:0\", shape=(154, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_17:0\", shape=(786,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_16:0\", shape=(786, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_20:0\", shape=(522,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_19:0\", shape=(522, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_23:0\", shape=(52,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_22:0\", shape=(52, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_11:0\", shape=(154,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_10:0\", shape=(154, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_13:0\", shape=(786,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_12:0\", shape=(786, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_15:0\", shape=(522,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_14:0\", shape=(522, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_17:0\", shape=(52,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_16:0\", shape=(52, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_14:0\", shape=(154,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_13:0\", shape=(154, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_17:0\", shape=(786,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_16:0\", shape=(786, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_20:0\", shape=(522,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_19:0\", shape=(522, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_23:0\", shape=(52,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_22:0\", shape=(52, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_51/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_conv_51/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_25/graph_pool_50/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 22.212144\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.531157\n",
            "Validation ROC-AUC Score: 0.483773\n",
            "Epoch 1 loss: 9.859675\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.674257\n",
            "Validation ROC-AUC Score: 0.732067\n",
            "Epoch 2 loss: 10.439037\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.750547\n",
            "Validation ROC-AUC Score: 0.725167\n",
            "Epoch 3 loss: 35.194679\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.805913\n",
            "Validation ROC-AUC Score: 0.741470\n",
            "Epoch 4 loss: 3.220647\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.803769\n",
            "Validation ROC-AUC Score: 0.705755\n",
            "Epoch 5 loss: 4.447469\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.821644\n",
            "Validation ROC-AUC Score: 0.748256\n",
            "Epoch 6 loss: 6.460313\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.873291\n",
            "Validation ROC-AUC Score: 0.680467\n",
            "Epoch 7 loss: 14.245310\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.857842\n",
            "Validation ROC-AUC Score: 0.702912\n",
            "Epoch 8 loss: 3.071784\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.855396\n",
            "Validation ROC-AUC Score: 0.739346\n",
            "Epoch 9 loss: 2.621143\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.891002\n",
            "Validation ROC-AUC Score: 0.740825\n",
            "Epoch 10 loss: 4.233685\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.882720\n",
            "Validation ROC-AUC Score: 0.688277\n",
            "Epoch 11 loss: 8.381221\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.906384\n",
            "Validation ROC-AUC Score: 0.726418\n",
            "Epoch 12 loss: 6.064122\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.909507\n",
            "Validation ROC-AUC Score: 0.737602\n",
            "Epoch 13 loss: 1.672430\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.920492\n",
            "Validation ROC-AUC Score: 0.731347\n",
            "Epoch 14 loss: 2.496207\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.926107\n",
            "Validation ROC-AUC Score: 0.697793\n",
            "Epoch 15 loss: 3.213392\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.932928\n",
            "Validation ROC-AUC Score: 0.713072\n",
            "Epoch 16 loss: 12.534755\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.940373\n",
            "Validation ROC-AUC Score: 0.719404\n",
            "Epoch 17 loss: 0.982928\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.938424\n",
            "Validation ROC-AUC Score: 0.704921\n",
            "Epoch 18 loss: 1.063326\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.930216\n",
            "Validation ROC-AUC Score: 0.706703\n",
            "Epoch 19 loss: 1.573468\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.949480\n",
            "Validation ROC-AUC Score: 0.709281\n",
            "Epoch 20 loss: 3.772028\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.947331\n",
            "Validation ROC-AUC Score: 0.745943\n",
            "Epoch 21 loss: 0.586277\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.938751\n",
            "Validation ROC-AUC Score: 0.690817\n",
            "Epoch 22 loss: 0.734414\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.946927\n",
            "Validation ROC-AUC Score: 0.717129\n",
            "Epoch 23 loss: 1.016137\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.945659\n",
            "Validation ROC-AUC Score: 0.781316\n",
            "Epoch 24 loss: 1.847055\n",
            "Evaluating model\n",
            "Training ROC-AUC Score: 0.939815\n",
            "Validation ROC-AUC Score: 0.736768\n"
          ]
        }
      ],
      "source": [
        "#Here is the GraphConv portion\n",
        "\n",
        "from deepchem.models import GraphConvModel\n",
        "\n",
        "# define a splitter \n",
        "splitter = dc.splits.SingletaskStratifiedSplitter() #ScaffoldSplitter\n",
        "\n",
        "# split dataset into train, test subsets (80% - 20%)\n",
        "train_dataset, val_dataset= splitter.train_test_split(dataset_6, \n",
        "                                                       seed=80,\n",
        "                                                       frac_train=0.8, \n",
        "                                                       verbose=False)\n",
        "print('Full dataset samples : {}'.format(dataset_6.X.shape[0]))\n",
        "print('Train dataset samples : {}'.format(train_dataset.X.shape[0]))\n",
        "print('Validation dataset samples : {}'.format(val_dataset.X.shape[0]))\n",
        "\n",
        "model = GraphConvModel(\n",
        "    len(task6), batch_size=batch_size, mode='classification',\n",
        "    dropout=n_dropout,\n",
        "    # model_dir='/content/drive/My Drive/MyProjects/DeepChem/antivirals/models/oneSplitMoreEpochs',\n",
        "    random_seed=42) # same seed here!\n",
        "# check the error for optimal number of epochs\n",
        "num_epochs = 25\n",
        "     \n",
        "losses = []\n",
        "auroc_train = []\n",
        "auroc_val = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  loss = model.fit(train_dataset, nb_epoch=1, deterministic=True)\n",
        "  print(\"Epoch %d loss: %f\" % (i, loss))\n",
        "  losses.append(loss)\n",
        "\n",
        "  # print statistics\n",
        "  print(\"Evaluating model\")\n",
        "  train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "  print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
        "  val_scores = model.evaluate(val_dataset, [metric], transformers)\n",
        "  print(\"Validation ROC-AUC Score: %f\" % val_scores[\"mean-roc_auc_score\"])\n",
        "\n",
        "  auroc_train.append(train_scores[\"mean-roc_auc_score\"])\n",
        "  auroc_val.append(val_scores[\"mean-roc_auc_score\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pB4Hq-nqddVn",
        "outputId": "70423621-c1f8-4a0a-b577-0e6ab6c35d91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "# plot the errors\n",
        "plot.ylabel(\"Loss\")\n",
        "plot.xlabel(\"Epoch\")\n",
        "x = range(num_epochs)\n",
        "y = losses\n",
        "plot.scatter(x, y)\n",
        "plot.plot(x,y)\n",
        "plot.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "fQY2dx6mOgrj",
        "outputId": "d108e9a5-4149-4d7d-9486-6ee5b31a9792"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "# plot the auroc train\n",
        "\n",
        "plot.ylabel(\"AUROC train\")\n",
        "plot.xlabel(\"Epoch\")\n",
        "x = range(num_epochs)\n",
        "y = auroc_train\n",
        "plot.scatter(x, y)\n",
        "plot.plot(x,y)\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rZVlQ0C1yZgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "55899cc2-1740-4f68-a049-ec31c2536939"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-295915cc1569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwhole_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Drug Activity Challenge/smiles_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwhole_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_task1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "#Reading the test data to prepare for predictions\n",
        "whole_test_data = test_df = pd.read_csv(\"/content/drive/MyDrive/Drug Activity Challenge/smiles_test.csv\")\n",
        "whole_test_data.to_csv('test_task1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f2_IjE7rZ8y"
      },
      "outputs": [],
      "source": [
        "#GEtting the molecules ready for prediction\n",
        "smiles = test_df['smiles'].tolist()\n",
        "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
        "x = featurizer.featurize(mols)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uUsZgw5MWYRF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "27c5392f-6567-4d17-9a47-a79db286a33d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7a41c720e6ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtask1df_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'task1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task1_preds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "#Saving the predictions on the first task to a separate CSV file\n",
        "preds = model.predict_on_batch(x,transformers)\n",
        "task1df_preds = pd.DataFrame(preds[:,0][:,1] , columns = ['task1']).to_csv('task1_preds.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tt5tfzp_jQL",
        "outputId": "84ea1524-6734-450c-a710-7e48a3641462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             task1         task2     task3     task4         task5     task6  \\\n",
            "0     1.893660e-02  1.687613e-05  0.448330  0.718237  2.212372e-03  0.205099   \n",
            "1     1.000000e+00  5.642028e-15  0.998580  0.024549  4.310642e-21  0.033133   \n",
            "2     7.967982e-03  5.196416e-05  0.897674  0.028955  1.271797e-01  0.054374   \n",
            "3     1.128658e-03  3.065134e-01  0.913400  0.001344  8.803573e-11  0.104767   \n",
            "4     2.910174e-18  3.012651e-09  0.865378  0.008347  7.108838e-21  0.281405   \n",
            "...            ...           ...       ...       ...           ...       ...   \n",
            "5891  1.525340e-09  7.223643e-05  0.998673  0.052426  8.541948e-15  0.042283   \n",
            "5892  8.255319e-10  9.052659e-01  0.934820  0.003052  4.337070e-12  0.000711   \n",
            "5893  3.705291e-06  1.960848e-06  0.823188  0.025968  1.935352e-16  0.174177   \n",
            "5894  1.000000e+00  1.580674e-15  0.879845  0.011599  9.003604e-21  0.035946   \n",
            "5895  6.104921e-07  5.205805e-07  0.577471  0.008174  4.997238e-02  0.308028   \n",
            "\n",
            "         task7     task8     task9    task10    task11  \n",
            "0     0.682333  0.999826  0.975874  0.574712  0.938528  \n",
            "1     0.060501  1.000000  0.411659  0.000783  0.787687  \n",
            "2     0.976938  0.296998  0.964343  0.743431  0.976619  \n",
            "3     0.542180  1.000000  0.888777  0.275456  0.906663  \n",
            "4     0.040011  1.000000  0.787504  0.998679  0.640052  \n",
            "...        ...       ...       ...       ...       ...  \n",
            "5891  0.554479  1.000000  0.670419  0.002168  0.900386  \n",
            "5892  0.811762  1.000000  0.925193  0.530755  0.972616  \n",
            "5893  0.740130  1.000000  0.937933  0.257653  0.736786  \n",
            "5894  0.029149  1.000000  0.838197  0.006205  0.715771  \n",
            "5895  0.030427  1.000000  0.066740  0.011744  0.648573  \n",
            "\n",
            "[5896 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "#Gathering all the predictions into one file for submission\n",
        "\n",
        "\n",
        "task1_preds_df = df = pd.read_csv(\"/content/task1_preds.csv\")\n",
        "task2_preds_df = df = pd.read_csv(\"/content/task2_preds.csv\")\n",
        "task3_preds_df = df = pd.read_csv(\"/content/task3_preds.csv\")\n",
        "task4_preds_df = df = pd.read_csv(\"/content/task4_preds.csv\")\n",
        "task5_preds_df = df = pd.read_csv(\"/content/task5_preds.csv\")\n",
        "task6_preds_df = df = pd.read_csv(\"/content/task6_preds.csv\")\n",
        "task7_preds_df = df = pd.read_csv(\"/content/task7_preds.csv\")\n",
        "task8_preds_df = df = pd.read_csv(\"/content/task8_preds.csv\")\n",
        "task9_preds_df = df = pd.read_csv(\"/content/task9_preds.csv\")\n",
        "task10_preds_df = df = pd.read_csv(\"/content/task10_preds.csv\")\n",
        "task11_preds_df = df = pd.read_csv(\"/content/task11_preds.csv\")\n",
        "\n",
        "frames = [task1_preds_df,task2_preds_df,task3_preds_df,task4_preds_df,task5_preds_df,task6_preds_df,task7_preds_df,task8_preds_df,task9_preds_df,task10_preds_df,task11_preds_df]\n",
        "\n",
        "result = pd.concat(frames,axis = 1)\n",
        "result =  result[['task1','task2','task3','task4','task5','task6','task7','task8','task9','task10','task11']]\n",
        "print(result)\n",
        "\n",
        "result.to_csv('result.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXkQ_NYvArVu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Ails Challenge 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}